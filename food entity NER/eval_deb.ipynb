{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    TextClassificationPipeline,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((0, 1),clip=True)\n",
    "scaler.fit([[0], [100]])\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 3e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19380</th>\n",
       "      <td>In bottom of 13 x 9 x 2-inch baking dish, spre...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>Last 15 minutes, add frozen peas.</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60047</th>\n",
       "      <td>Add 1/8 teaspoon salt and shortening.</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27793</th>\n",
       "      <td>Add rice, broccoli and salt and pepper to tast...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65878</th>\n",
       "      <td>25 to 30 minutes. Cool. Sift confectioners sug...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71030</th>\n",
       "      <td>Mix in 1 whole egg and 3 egg yolks.</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>When meat balls are done, add tomato sauce and...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33741</th>\n",
       "      <td>Add the remaining 1/3 of milk and beat.</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30476</th>\n",
       "      <td>Fill mushroom caps with the crab mixture and b...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73708</th>\n",
       "      <td>Grease 2 casserole dishes.</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences  \\\n",
       "19380  In bottom of 13 x 9 x 2-inch baking dish, spre...   \n",
       "11091                  Last 15 minutes, add frozen peas.   \n",
       "60047              Add 1/8 teaspoon salt and shortening.   \n",
       "27793  Add rice, broccoli and salt and pepper to tast...   \n",
       "65878  25 to 30 minutes. Cool. Sift confectioners sug...   \n",
       "...                                                  ...   \n",
       "71030                Mix in 1 whole egg and 3 egg yolks.   \n",
       "22451  When meat balls are done, add tomato sauce and...   \n",
       "33741            Add the remaining 1/3 of milk and beat.   \n",
       "30476  Fill mushroom caps with the crab mixture and b...   \n",
       "73708                         Grease 2 casserole dishes.   \n",
       "\n",
       "                                                     tag  \n",
       "19380  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "11091                                 [0, 0, 0, 0, 0, 1]  \n",
       "60047                                 [0, 0, 0, 1, 0, 0]  \n",
       "27793   [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2]  \n",
       "65878                     [0, 0, 0, 0, 0, 0, 1, 2, 0, 0]  \n",
       "...                                                  ...  \n",
       "71030                        [0, 0, 0, 0, 1, 0, 0, 1, 2]  \n",
       "22451  [0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "33741                           [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "30476  [0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "73708                                       [0, 0, 1, 0]  \n",
       "\n",
       "[7708 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(\"test_deb_ner_nolora.gzip\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForTokenClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./deb-ner-nolora-output/checkpoint-19260/\"\n",
    "id2label = {0:0, 1:1, 2:2}\n",
    "label2id = {v:k for i,(k, v) in enumerate(id2label.items())}\n",
    "model_c = transformers.AutoModelForTokenClassification.from_pretrained(model_path, \n",
    "                                                                        num_labels=3,\n",
    "                                                                        id2label=id2label,\n",
    "                                                                        label2id=label2id)\n",
    "model_c.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]['sentences']\n",
    "data.iloc[0]['tag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51907</th>\n",
       "      <td>Shape as desired and roll in 1/2 of dried beef.</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences  \\\n",
       "51907  Shape as desired and roll in 1/2 of dried beef.   \n",
       "\n",
       "                                  tag  \n",
       "51907  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data.sample(1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 0\n",
      "bottom 0\n",
      "of 0\n",
      "13 0\n",
      "x 0\n",
      "9 0\n",
      "x 0\n",
      "2-inch 0\n",
      "baking 0\n",
      "dish, 0\n",
      "spread 0\n",
      "1/2 0\n",
      "of 0\n",
      "meat 1\n",
      "mixture. 0\n",
      "Top 0\n",
      "with 0\n",
      "5 0\n",
      "tortillas 1\n",
      "and 0\n",
      "top 0\n",
      "with 0\n",
      "1/2 0\n",
      "Ricotta 1\n",
      "cheese 2\n",
      "mixture. 2\n",
      "Top 2\n",
      "with 2\n",
      "1/2 2\n",
      "Monterey 1\n",
      "Jack 2\n",
      "cheese, 2\n",
      "repeat 0\n",
      "layering, 0\n",
      "ending 0\n",
      "with 0\n",
      "cheese. 1\n",
      "Bake, 0\n",
      "uncovered, 0\n",
      "in 0\n",
      "350 0\n",
      "degrees 0\n",
      "oven 0\n",
      "20 0\n",
      "to 0\n",
      "30 0\n",
      "minutes. 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data.iloc[0]['tag'])):\n",
    "    print(data.iloc[0]['sentences'].split()[i], data.iloc[0]['tag'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_tokens(original, ids, og_tag):\n",
    "    tokens = (tokenizer.convert_ids_to_tokens([int(i) for i in ids]))\n",
    "    tagt = [0]\n",
    "    tsplit = original.split()\n",
    "    sent_ind = 0\n",
    "    token_ind = 0\n",
    "    puncs = ';:.,()-\"\\''\n",
    "    # tag tokens\n",
    "    while sent_ind < (len(tsplit)):\n",
    "        while token_ind < len(tokens):\n",
    "            if tokens[token_ind]=='[CLS]':\n",
    "                token_ind += 1\n",
    "                continue\n",
    "            temp_t = tokens[token_ind]\n",
    "            temp_t = temp_t.replace('▁', '')\n",
    "            # print(temp_t, tsplit[sent_ind])\n",
    "            if temp_t in puncs:\n",
    "                tagt.append(0)\n",
    "                token_ind += 1\n",
    "            elif temp_t in tsplit[sent_ind]:\n",
    "                tagt.append(og_tag[sent_ind])\n",
    "                token_ind += 1\n",
    "            else:\n",
    "                break\n",
    "        sent_ind += 1\n",
    "    tagt += [0]\n",
    "    # tagt += [0]*(MAX_LEN-len(tagt))\n",
    "    # print(len(tagt))\n",
    "    # for i in range(len(tokens)):\n",
    "    #     print(tokens[i], tagt[i])\n",
    "    return tagt[1:-1]\n",
    "def tok_align(data):\n",
    "    labels = []\n",
    "    encodings = tokenizer.batch_encode_plus(\n",
    "                    data['sentences'].tolist(),\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=MAX_LEN,\n",
    "                    padding='max_length',\n",
    "                    return_token_type_ids=True,\n",
    "                    truncation=True\n",
    "                )\n",
    "    for i in range(len(data)):\n",
    "        # print(data.tag.iloc[i])\n",
    "        labels.append(tag_tokens(data.sentences.iloc[i], encodings['input_ids'][i], data.tag.iloc[i]))\n",
    "    # return encodings, labels\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlabels = tok_align(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7708"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class logitpipeline(TextClassificationPipeline):\n",
    "#     def postprocess(self, model_outputs):\n",
    "#         best_class = model_outputs[\"logits\"]\n",
    "#         return best_class\n",
    "pipe = pipeline(task = 'ner', model=model_c, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 0, 'score': 0.9999833, 'index': 1, 'word': '▁Prepare', 'start': 0, 'end': 7}, {'entity': 0, 'score': 0.8667542, 'index': 2, 'word': '▁hot', 'start': 7, 'end': 11}, {'entity': 1, 'score': 0.87873846, 'index': 3, 'word': '▁roll', 'start': 11, 'end': 16}, {'entity': 0, 'score': 0.9946467, 'index': 4, 'word': '▁mix', 'start': 16, 'end': 20}, {'entity': 0, 'score': 0.99962556, 'index': 5, 'word': '▁with', 'start': 20, 'end': 25}, {'entity': 0, 'score': 0.99834263, 'index': 6, 'word': '▁one', 'start': 25, 'end': 29}, {'entity': 1, 'score': 0.9993818, 'index': 7, 'word': '▁egg', 'start': 29, 'end': 33}, {'entity': 0, 'score': 0.99919266, 'index': 8, 'word': '▁and', 'start': 33, 'end': 37}, {'entity': 0, 'score': 0.9995092, 'index': 9, 'word': '▁let', 'start': 37, 'end': 41}, {'entity': 0, 'score': 0.99944216, 'index': 10, 'word': '▁rise', 'start': 41, 'end': 46}, {'entity': 0, 'score': 0.9999945, 'index': 11, 'word': '.', 'start': 46, 'end': 47}, {'entity': 0, 'score': 0.9999337, 'index': 12, 'word': '▁Beat', 'start': 47, 'end': 52}, {'entity': 0, 'score': 0.99212426, 'index': 13, 'word': '▁other', 'start': 52, 'end': 58}, {'entity': 1, 'score': 0.9597315, 'index': 14, 'word': '▁egg', 'start': 58, 'end': 62}, {'entity': 0, 'score': 0.9962929, 'index': 15, 'word': '▁in', 'start': 62, 'end': 65}, {'entity': 0, 'score': 0.99431205, 'index': 16, 'word': '▁a', 'start': 65, 'end': 67}, {'entity': 0, 'score': 0.99956113, 'index': 17, 'word': '▁cup', 'start': 67, 'end': 71}, {'entity': 0, 'score': 0.9999933, 'index': 18, 'word': '.', 'start': 71, 'end': 72}, {'entity': 0, 'score': 0.99993515, 'index': 19, 'word': '▁Stir', 'start': 72, 'end': 77}, {'entity': 0, 'score': 0.9998654, 'index': 20, 'word': '▁in', 'start': 77, 'end': 80}, {'entity': 1, 'score': 0.9999471, 'index': 21, 'word': '▁cheese', 'start': 80, 'end': 87}, {'entity': 0, 'score': 0.9999858, 'index': 22, 'word': '.', 'start': 87, 'end': 88}, {'entity': 0, 'score': 0.9998807, 'index': 23, 'word': '▁Heat', 'start': 88, 'end': 93}, {'entity': 0, 'score': 0.99988925, 'index': 24, 'word': '▁remaining', 'start': 93, 'end': 103}, {'entity': 0, 'score': 0.99704546, 'index': 25, 'word': '▁ingredients', 'start': 103, 'end': 115}, {'entity': 0, 'score': 0.9969465, 'index': 26, 'word': '▁in', 'start': 115, 'end': 118}, {'entity': 0, 'score': 0.99967957, 'index': 27, 'word': '▁small', 'start': 118, 'end': 124}, {'entity': 0, 'score': 0.9991641, 'index': 28, 'word': '▁saucepan', 'start': 124, 'end': 133}, {'entity': 0, 'score': 0.99991536, 'index': 29, 'word': '▁until', 'start': 133, 'end': 139}, {'entity': 0, 'score': 0.593927, 'index': 30, 'word': '▁greens', 'start': 139, 'end': 146}, {'entity': 0, 'score': 0.99506843, 'index': 31, 'word': '▁wilt', 'start': 146, 'end': 151}, {'entity': 0, 'score': 0.99999166, 'index': 32, 'word': '.', 'start': 151, 'end': 152}, {'entity': 0, 'score': 0.999616, 'index': 33, 'word': '▁Cool', 'start': 152, 'end': 157}, {'entity': 0, 'score': 0.9994611, 'index': 34, 'word': '▁and', 'start': 157, 'end': 161}, {'entity': 0, 'score': 0.9992793, 'index': 35, 'word': '▁blend', 'start': 161, 'end': 167}, {'entity': 0, 'score': 0.99963236, 'index': 36, 'word': '▁in', 'start': 167, 'end': 170}, {'entity': 0, 'score': 0.99929726, 'index': 37, 'word': '▁beaten', 'start': 170, 'end': 177}, {'entity': 1, 'score': 0.99978393, 'index': 38, 'word': '▁egg', 'start': 177, 'end': 181}, {'entity': 2, 'score': 0.99272174, 'index': 39, 'word': '▁mix', 'start': 181, 'end': 185}, {'entity': 0, 'score': 0.9998772, 'index': 40, 'word': '.', 'start': 185, 'end': 186}, {'entity': 2, 'score': 0.9672395, 'index': 41, 'word': '▁Punch', 'start': 186, 'end': 192}, {'entity': 2, 'score': 0.96931064, 'index': 42, 'word': '▁down', 'start': 192, 'end': 197}, {'entity': 2, 'score': 0.9680112, 'index': 43, 'word': '▁dough', 'start': 197, 'end': 203}, {'entity': 0, 'score': 0.99992347, 'index': 44, 'word': '.', 'start': 203, 'end': 204}, {'entity': 2, 'score': 0.96505386, 'index': 45, 'word': '▁Knead', 'start': 204, 'end': 210}, {'entity': 2, 'score': 0.9653589, 'index': 46, 'word': '▁a', 'start': 210, 'end': 212}, {'entity': 2, 'score': 0.9669238, 'index': 47, 'word': '▁few', 'start': 212, 'end': 216}, {'entity': 2, 'score': 0.9693252, 'index': 48, 'word': '▁times', 'start': 216, 'end': 222}, {'entity': 0, 'score': 0.9999503, 'index': 49, 'word': '.', 'start': 222, 'end': 223}, {'entity': 2, 'score': 0.95775443, 'index': 50, 'word': '▁Roll', 'start': 223, 'end': 228}, {'entity': 2, 'score': 0.9595418, 'index': 51, 'word': '▁out', 'start': 228, 'end': 232}, {'entity': 2, 'score': 0.9293594, 'index': 52, 'word': '▁to', 'start': 232, 'end': 235}, {'entity': 2, 'score': 0.92337114, 'index': 53, 'word': '▁an', 'start': 235, 'end': 238}, {'entity': 2, 'score': 0.94709706, 'index': 54, 'word': '▁18', 'start': 238, 'end': 241}, {'entity': 2, 'score': 0.93937045, 'index': 55, 'word': '▁x', 'start': 241, 'end': 243}, {'entity': 2, 'score': 0.9404888, 'index': 56, 'word': '▁6', 'start': 243, 'end': 245}, {'entity': 2, 'score': 0.9273502, 'index': 57, 'word': '▁rectangle', 'start': 245, 'end': 255}, {'entity': 0, 'score': 0.9999683, 'index': 58, 'word': '.', 'start': 255, 'end': 256}, {'entity': 2, 'score': 0.93061495, 'index': 59, 'word': '▁Spread', 'start': 256, 'end': 263}, {'entity': 2, 'score': 0.92565554, 'index': 60, 'word': '▁with', 'start': 263, 'end': 268}, {'entity': 1, 'score': 0.9996057, 'index': 61, 'word': '▁parsley', 'start': 268, 'end': 276}, {'entity': 2, 'score': 0.99558604, 'index': 62, 'word': '▁mix', 'start': 276, 'end': 280}, {'entity': 0, 'score': 0.99930525, 'index': 63, 'word': '.', 'start': 280, 'end': 281}, {'entity': 2, 'score': 0.96963364, 'index': 64, 'word': '▁Roll', 'start': 281, 'end': 286}, {'entity': 1, 'score': 0.9947339, 'index': 65, 'word': '▁jelly', 'start': 286, 'end': 292}, {'entity': 2, 'score': 0.9565162, 'index': 66, 'word': '▁fashion', 'start': 292, 'end': 300}, {'entity': 2, 'score': 0.94235325, 'index': 67, 'word': '▁and', 'start': 300, 'end': 304}, {'entity': 2, 'score': 0.9583919, 'index': 68, 'word': '▁place', 'start': 304, 'end': 310}, {'entity': 2, 'score': 0.9503293, 'index': 69, 'word': '▁seam', 'start': 310, 'end': 315}, {'entity': 2, 'score': 0.9489146, 'index': 70, 'word': '▁side', 'start': 315, 'end': 320}, {'entity': 2, 'score': 0.9510897, 'index': 71, 'word': '▁down', 'start': 320, 'end': 325}, {'entity': 2, 'score': 0.9551426, 'index': 72, 'word': '▁in', 'start': 325, 'end': 328}, {'entity': 2, 'score': 0.9518245, 'index': 73, 'word': '▁greased', 'start': 328, 'end': 336}, {'entity': 2, 'score': 0.9465773, 'index': 74, 'word': '▁9', 'start': 336, 'end': 338}, {'entity': 2, 'score': 0.9517017, 'index': 75, 'word': '▁x', 'start': 338, 'end': 340}, {'entity': 2, 'score': 0.94113094, 'index': 76, 'word': '▁5', 'start': 340, 'end': 342}, {'entity': 2, 'score': 0.93905157, 'index': 77, 'word': '▁x', 'start': 342, 'end': 344}, {'entity': 2, 'score': 0.9381329, 'index': 78, 'word': '▁3', 'start': 344, 'end': 346}, {'entity': 2, 'score': 0.93462783, 'index': 79, 'word': '▁pan', 'start': 346, 'end': 350}, {'entity': 0, 'score': 0.99993265, 'index': 80, 'word': '.', 'start': 350, 'end': 351}, {'entity': 2, 'score': 0.9241946, 'index': 81, 'word': '▁Cover', 'start': 351, 'end': 357}, {'entity': 0, 'score': 0.9999454, 'index': 82, 'word': '.', 'start': 357, 'end': 358}, {'entity': 2, 'score': 0.9090574, 'index': 83, 'word': '▁Let', 'start': 358, 'end': 362}, {'entity': 2, 'score': 0.9082499, 'index': 84, 'word': '▁rise', 'start': 362, 'end': 367}, {'entity': 2, 'score': 0.8879242, 'index': 85, 'word': '▁again', 'start': 367, 'end': 373}, {'entity': 2, 'score': 0.8195226, 'index': 86, 'word': '▁until', 'start': 373, 'end': 379}, {'entity': 2, 'score': 0.87419105, 'index': 87, 'word': '▁double', 'start': 379, 'end': 386}, {'entity': 2, 'score': 0.8577144, 'index': 88, 'word': '▁in', 'start': 386, 'end': 389}, {'entity': 2, 'score': 0.86435735, 'index': 89, 'word': '▁size', 'start': 389, 'end': 394}, {'entity': 0, 'score': 0.99980956, 'index': 90, 'word': '▁(', 'start': 394, 'end': 396}, {'entity': 2, 'score': 0.830263, 'index': 91, 'word': 'about', 'start': 396, 'end': 401}, {'entity': 2, 'score': 0.85919505, 'index': 92, 'word': '▁45', 'start': 401, 'end': 404}, {'entity': 2, 'score': 0.8597415, 'index': 93, 'word': '▁minutes', 'start': 404, 'end': 412}, {'entity': 0, 'score': 0.99996614, 'index': 94, 'word': '▁)', 'start': 412, 'end': 414}, {'entity': 0, 'score': 0.99996364, 'index': 95, 'word': '.', 'start': 414, 'end': 415}, {'entity': 2, 'score': 0.8291329, 'index': 96, 'word': '▁Bake', 'start': 415, 'end': 420}, {'entity': 2, 'score': 0.8487589, 'index': 97, 'word': '▁at', 'start': 420, 'end': 423}, {'entity': 2, 'score': 0.8453681, 'index': 98, 'word': '▁375', 'start': 423, 'end': 427}, {'entity': 2, 'score': 0.8531553, 'index': 99, 'word': '▁degrees', 'start': 427, 'end': 435}, {'entity': 2, 'score': 0.81142014, 'index': 100, 'word': '▁for', 'start': 435, 'end': 439}, {'entity': 2, 'score': 0.8238904, 'index': 101, 'word': '▁45', 'start': 439, 'end': 442}, {'entity': 2, 'score': 0.82840395, 'index': 102, 'word': '▁minutes', 'start': 442, 'end': 450}, {'entity': 2, 'score': 0.79705995, 'index': 103, 'word': '▁or', 'start': 450, 'end': 453}, {'entity': 2, 'score': 0.71472543, 'index': 104, 'word': '▁until', 'start': 453, 'end': 459}, {'entity': 1, 'score': 0.9998404, 'index': 105, 'word': '▁bread', 'start': 459, 'end': 465}, {'entity': 2, 'score': 0.69013375, 'index': 106, 'word': '▁gives', 'start': 465, 'end': 471}, {'entity': 2, 'score': 0.69019204, 'index': 107, 'word': '▁a', 'start': 471, 'end': 473}, {'entity': 2, 'score': 0.63666105, 'index': 108, 'word': '▁hollow', 'start': 473, 'end': 480}, {'entity': 2, 'score': 0.6663922, 'index': 109, 'word': '▁sound', 'start': 480, 'end': 486}, {'entity': 2, 'score': 0.65865505, 'index': 110, 'word': '▁when', 'start': 486, 'end': 491}, {'entity': 2, 'score': 0.59405434, 'index': 111, 'word': '▁tapped', 'start': 491, 'end': 498}, {'entity': 0, 'score': 0.99998283, 'index': 112, 'word': '.', 'start': 498, 'end': 499}]\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "2 2\n",
      "1 1\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "1 1\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "0 0\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "0 0\n",
      "0 0\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "1 1\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "df1 = data.sample(1)\n",
    "t1 = tok_align(df1)\n",
    "pred = pipe(df1.iloc[0]['sentences'])\n",
    "print(pred)\n",
    "for i in range(len(t1[0])):\n",
    "    print(pred[i]['entity'], t1[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingr = data.sentences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    for i in range(len(ingr)):\n",
    "        yield ingr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7700\r"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "count = 0\n",
    "for out in pipe(data()):\n",
    "    count += 1\n",
    "    if count % 100 ==0:\n",
    "        print(count, end='\\r')\n",
    "    output.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "newoutput = [[i['entity'] for i in j] for j in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(newoutput)):\n",
    "    if len(newoutput[i]) != len(outlabels[i]):\n",
    "        print(newoutput[i])\n",
    "        print(outlabels[i])\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({\"output\":newoutput, 'labels':outlabels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 2, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7707</th>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 output  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1                              [0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "2                           [0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "3     [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0]   \n",
       "...                                                 ...   \n",
       "7703                     [0, 0, 0, 0, 1, 0, 0, 1, 2, 0]   \n",
       "7704  [0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "7705                  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "7706  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7707                                    [0, 0, 1, 0, 0]   \n",
       "\n",
       "                                                 labels  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1                              [0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "2                           [0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "3     [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4            [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0]  \n",
       "...                                                 ...  \n",
       "7703                     [0, 0, 0, 0, 1, 0, 0, 1, 2, 0]  \n",
       "7704  [0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...  \n",
       "7705                  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "7706  [0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7707                                    [0, 0, 1, 0, 0]  \n",
       "\n",
       "[7708 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_parquet(\"pred_deb_nolora.gzip\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.217041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.010872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.000275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        output\n",
       "0    -0.003521\n",
       "1     0.003441\n",
       "2     0.077698\n",
       "3     0.217041\n",
       "4    -0.000684\n",
       "...        ...\n",
       "9995  0.010872\n",
       "9996 -0.001085\n",
       "9997 -0.004082\n",
       "9998  0.001297\n",
       "9999 -0.000275\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodings = tokenizer.batch_encode_plus(\n",
    "#                     data['sentences'].tolist(),\n",
    "#                     add_special_tokens=True,\n",
    "#                     max_length=MAX_LEN,\n",
    "#                     padding='max_length',\n",
    "#                     return_token_type_ids=True,\n",
    "#                     truncation=True,\n",
    "#                     return_tensors=\"pt\"\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# def enc(sent)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m encodings \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m      3\u001b[0m                     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      4\u001b[0m                     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m                     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m                 )\n\u001b[1;32m---> 11\u001b[0m ret \u001b[38;5;241m=\u001b[39m [val\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m encodings\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     12\u001b[0m ret\n",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# def enc(sent)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m encodings \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m      3\u001b[0m                     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      4\u001b[0m                     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m                     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m                 )\n\u001b[1;32m---> 11\u001b[0m ret \u001b[38;5;241m=\u001b[39m [\u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m encodings\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     12\u001b[0m ret\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# # def enc(sent)\n",
    "# encodings = tokenizer.encode_plus(\n",
    "#                     data['sentences'].tolist()[0],\n",
    "#                     add_special_tokens=True,\n",
    "#                     max_length=MAX_LEN,\n",
    "#                     padding='max_length',\n",
    "#                     return_token_type_ids=True,\n",
    "#                     truncation=True,\n",
    "#                     return_tensors=\"pt\"\n",
    "#                 )\n",
    "# ret = [val.clone().detach().to(\"cuda\") for val in encodings.values()]\n",
    "# ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cooking_time_model(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(cooking_time_model, self).__init__()\n",
    "#         self.l1 = transformers.RobertaModel.from_pretrained(pretrained)\n",
    "#         self.l2 = torch.nn.Dropout(0.3)\n",
    "#         self.l3 = torch.nn.Linear(768, MAX_LEN)\n",
    "\n",
    "#     def forward(self, ids, mask, token_type_ids):\n",
    "#         output_1 = self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
    "#         output_2 = self.l2(output_1.pooler_output)\n",
    "#         output = self.l3(output_2)\n",
    "#         return output\n",
    "model_path = \"./drob-mfst-nolora-output/checkpoint-17500\"\n",
    "model_c = transformers.AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=1, load_in_8bit = True)\n",
    "model_c.config.problem_type = \"regression\"\n",
    "# model_c = cooking_time_model()\n",
    "# model_c.to(device)\n",
    "# def count_parameters(modelr):\n",
    "#     return sum(p.numel() for p in modelr.parameters() if p.requires_grad)\n",
    "\n",
    "# print(f'The model has {count_parameters(model_c):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_c\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 3\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:828\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    836\u001b[0m     embedding_output,\n\u001b[0;32m    837\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    845\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:132\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    130\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n\u001b[0;32m    131\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m--> 132\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\normalization.py:196\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\functional.py:2543\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2541\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2542\u001b[0m     )\n\u001b[1;32m-> 2543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model_c.eval()\n",
    "with torch.no_grad():\n",
    "    output = model_c(input_ids=ret[0],attention_mask=ret[1],token_type_ids=ret[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into\n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss\n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.00022455735384061483 0.00022455735384061483\n"
     ]
    }
   ],
   "source": [
    "model_best, _, _, l1 = load_ckp(\"best_model_a3.pt\", model_c, optimizer)\n",
    "model_current, _, _, l2 = load_ckp(\"current_checkpoint_a3.pt\", model_c, optimizer)\n",
    "print(l1==l2)\n",
    "print(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~ 69950/69998(0.9993142661218892) ~~~~~~~~~~~~~~~~\r"
     ]
    }
   ],
   "source": [
    "def submission(dataloader, model_selected): # Code for submission\n",
    "    preds = []\n",
    "    targets = []\n",
    "    model_selected.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (id, mask, tokentype, target) in enumerate(dataloader):\n",
    "            outputs = model_selected(id, mask, tokentype)\n",
    "            preds.append(list(outputs.logits))\n",
    "            targets.append(list(target))\n",
    "            if (batch_idx+1)%50 == 0:\n",
    "                print(\"~\"*15,f\"{batch_idx+1}/{len(dataloader)}({(batch_idx+1)/len(dataloader)})\",\"~\"*15, end=\"\\r\")\n",
    "            \n",
    "    return preds, targets\n",
    "ret, tar = submission(test_loader, model_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltar = [l[0].tolist() for l in tar]\n",
    "lret = [l[0].tolist()[0] for l in ret]\n",
    "ltar = [round(l, 4) for l in ltar]\n",
    "lret = [round(l, 4) if l>=0 else 0 for l in lret]\n",
    "# lret = [l[0] for l in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006316959055973027\n"
     ]
    }
   ],
   "source": [
    "# for p, r in zip(ltar, lret):\n",
    "#     # print(p, r)\n",
    "#     print(abs(p-r)*100)\n",
    "err = [abs(p-r) for p,r in zip(ltar,lret)]\n",
    "print(np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error stats:\n",
      "average: 0.6316959055973027\n",
      "max: 92.7\n",
      "max error target(minutes) 93.5\n",
      "max error prediction(minutes) 0.8\n",
      "max error recipe:\n",
      "1 elephant, 2 rabbits (optional), 2 pails salt, 1 (8 oz.) canister black pepper, 3 bushels onions, <mask> gal. water, 6 pails flour\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((0, 1),clip=True)\n",
    "scaler.fit([[0], [100]])\n",
    "err_min = scaler.inverse_transform([[i] for i in err])\n",
    "# for m, e in zip(err_min, err):\n",
    "#     print(m[0], e)\n",
    "print(\"error stats:\")\n",
    "print(\"average:\", np.mean(err_min))\n",
    "print(\"max:\", *err_min[np.argmax(err_min)])\n",
    "print(\"max error target(minutes)\",(scaler.inverse_transform([[data.iloc[np.argmax(err_min)][1]]])[0][0]))\n",
    "print(\"max error prediction(minutes)\",scaler.inverse_transform([[lret[np.argmax(err_min)]]])[0][0])\n",
    "print(\"max error recipe:\")\n",
    "print(data.iloc[np.argmax(err_min)][0])\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08980672806501389\n",
      "8.980672806501389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_input = [\"<mask> lb. lean beef, cut across the grain into thin slices (you need a quick-cooking cut, such as minute steak), 1 lemongrass stalk, trimmed and finely chopped, <mask> tbsp. soy sauce, 2 tbs. fish sauce, 4 tsp. brown sugar, 0.5 tsp. chilli flakes, 1 lime, juiced, 3 tbsp. vegetable oil, 1 green pepper, thinly sliced, 2 bunches of spring onions, green and white parts separated and finely sliced, 6 garlic cloves, finely chopped, 1 tbsp. grated ginger, small bunch of basil, or purple basil, leaves picked and roughly chopped, cooked rice (about 250g uncooked weight), or cooked rice noodles, 50g roasted peanuts, roughly chopped\"]\n",
    "test_input = ['6 slices bacon, chopped, 0.5 c. chopped onion, <mask> c. chopped celery, 0.5 c. chopped green bell pepper, 3 cloves garlic, minced, 0.5 tsp. kosher salt, 0.5 tsp. freshly ground black pepper, 0.5 tsp. dried thyme, 0.25 tsp. cayenne pepper, 2 (12 ounce) packages frozen black-eyed peas, 4 c. reduced-sodium chicken broth, 2 c. cooked long grain rice, 0.25 c. chopped green onions, or as needed']\n",
    "# test_input = ['<mask> lb. lean beef, cut across the grain into thin slices (you need a quick-cooking cut, such as minute steak), 1 lemongrass stalk, trimmed and finely chopped, <mask> tbsp. soy sauce, 2 tbsp. fish sauce, 4 tsp. brown sugar, 0.5 tsp. chili flakes, 1 lime, juiced, 3 tbsp. vegetable oil, 1 green pepper, thinly sliced, 2 bunches of spring onions, green and white parts separated and finely sliced, 6 garlic cloves, finely chopped, 1 tbsp. grated ginger, small bunch of basil, or purple basil, leaves picked and roughly chopped, cooked rice (about 250g uncooked weight), or cooked rice noodles, 50g roasted peanuts, roughly chopped']\n",
    "test_input = [\"0.25 c. unsalted butter, 0.25 c. all-purpose flour, 1 medium onion, chopped, 1 c. chopped celery, 0.67 c. chopped red bell pepper, 0.67 c. chopped green bell pepper, 2 cloves garlic, minced, 2 tsp. Cajun seasoning, 0.5 c. chicken broth, 0.5 lb. thinly sliced, fully cooked smoked sausage, 0.25 tsp. crushed red pepper flakes, 0.5 tsp. freshly ground black pepper, salt to taste (see Cook's Notes), 0.5 lb. raw shrimp, peeled and deveined (see Cook's Notes), 0.5 c. heavy whipping cream, <mask> oz. spaghetti, cooked, chopped fresh parsley for garnish (optional), lemon slices for garnish (optional)\"]\n",
    "def test_pipeline(test_input):\n",
    "    single_df = pd.DataFrame({\"ingr\":test_input, \"tags\":[0.0]})\n",
    "    # single_df\n",
    "    s_test_customset = CustomDataset(single_df, tokenizer, MAX_LEN)\n",
    "    s_test_loader = DataLoader(s_test_customset, batch_size=1, shuffle=False, collate_fn=colbatch)\n",
    "    with torch.no_grad():\n",
    "        for _, (id, mask, tokentype, _) in enumerate(s_test_loader):\n",
    "            outputs = model_best(id, mask, tokentype)\n",
    "            print(outputs.logits.tolist()[0][0])\n",
    "            print(scaler.inverse_transform(outputs.logits.tolist())[0][0])\n",
    "            return(outputs.logits.tolist()[0][0])\n",
    "            \n",
    "            # return outputs.logits.tolist(), scaler.inverse_transform(outputs.logits.tolist())\n",
    "test_pipeline(test_input)\n",
    "scaler.transform([[12]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
